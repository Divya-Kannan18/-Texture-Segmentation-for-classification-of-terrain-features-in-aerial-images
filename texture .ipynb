{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import the necessary packages from imutils import paths import numpy as np\n",
    "import matplotlib.pyplot as plt import glob\n",
    "import math import argparse import imutils import cv2\n",
    "\n",
    "\n",
    "#IMAGE STITCHING\n",
    "\n",
    "# LOAD IMAGES\n",
    "\n",
    "print(\"[INFO] loading images...\") imagefiles = glob.glob(\"1.jpg/*\") imagefiargp\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) images.append(img)\n",
    "num_images = len(images)\n",
    "\n",
    "#Display images plt.figure(figsize=[30,10]) num_cols = 3\n",
    "num_rows = math.ceil(num_images / num_cols) for i in range(0, num_images):\n",
    "plt.subplot(num_rows, num_cols, i+1) plt.axis('off')\n",
    "plt.imshow(images[i])\n",
    "\n",
    "\n",
    "#STITCHING IMAGES\n",
    "\n",
    "print(\"[INFO] stitching images...\") stitcher = cv2.Stitcher_create()\n",
    "(status, stitched) = stitcher.stitch(images)\n",
    "\n",
    "stitched = cv2.cvtColor(stitched, cv2.COLOR_BGR2RGB) cv2.imwrite(\"./res/result.png\",stitched)\n",
    "# if the status is '0', then OpenCV successfully performed image stitching if status == 0:\n",
    "# display the output stitched image to our screen plt.figure(figsize=[30,10])\n",
    "plt.imshow(stitched) cv2.waitKey(0)\n",
    "# otherwise the stitching failed, likely due to not enough keypoints being detected else:\n",
    "print(\"[INFO] image stitching failed ({})\".format(status))\n",
    "\n",
    "#CROPPING IMAGE\n",
    "\n",
    "print(\"[INFO] cropping...\")\n",
    "\n",
    "stitched = cv2.copyMakeBorder(stitched, 10, 10, 10, 10, cv2.BORDER_CONSTANT,\n",
    "\n",
    "(0, 0, 0))\n",
    "\n",
    "\n",
    "# convert the stitched image to grayscale and threshold it # such that all pixels greater than zero are set to 255\n",
    "# (foreground) while all others remain 0 (background) gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY) plt.imshow(thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# find all external contours in the threshold image then find\n",
    "\n",
    "# the *largest* contour which will be the contour/outline of the stitched image cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "# allocate memory for the mask which will contain the rectangular bounding box of the stitched image region\n",
    "mask = np.zeros(thresh.shape, dtype=\"uint8\") (x, y, w, h) = cv2.boundingRect(c)\n",
    "cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)\n",
    "\n",
    "# create two copies of the mask: one to serve as our actual\n",
    "\n",
    "# minimum rectangular region and another to serve as a counter\n",
    "\n",
    "# for how many pixels need to be removed to form the minimum rectangular region minRect = mask.copy()\n",
    "sub = mask.copy()\n",
    "\n",
    "\n",
    "# keep looping until there are no non-zero pixels left in the subtracted image while cv2.countNonZero(sub) > 0:\n",
    "# erode the minimum rectangular mask and then subtract\n",
    "\n",
    "# the thresholded image from the minimum rectangular mask # so we can count if there are any non-zero pixels left\n",
    "minRect = cv2.erode(minRect, None) sub = cv2.subtract(minRect, thresh)\n",
    "\n",
    "\n",
    "# find contours in the minimum rectangular mask and then # extract the bounding box (x, y)-coordinates\n",
    "cnts = cv2.findContours(minRect.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "c = max(cnts, key=cv2.contourArea) (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "\n",
    "plt.imshow(minRect) cv2.waitKey(0)\n",
    "# use the bounding box coordinates to extract the our final\n",
    "\n",
    "# stitched image\n",
    "\n",
    "stitched = stitched[y:y + h, x:x + w]\n",
    "\n",
    "# write the output stitched image to disk cv2.imwrite(\"./res/final.png\", stitched)\n",
    "# display the output stitched image to our screen plt.imshow(stitched)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "#TEXTURE SEGMENTATION\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "\n",
    "img=io.imread(\"./res/final.png\", as_gray=True) plt.imshow(img,cmap=\"gray\")\n",
    "\n",
    "\n",
    "#threshold=filters.threshold_niblack(img) from scipy import ndimage\n",
    "k=20\n",
    "\n",
    "img_mean=ndimage.uniform_filter(img,(k,k)) img_sqr_mean=ndimage.uniform_filter(img**2,(k,k)) img_var=img_sqr_mean - img_mean**2 plt.imshow(img_var,cmap='gray')\n",
    "\n",
    "ksize=45 theta=np.pi/2\n",
    "\n",
    "kernel=cv2.getGaborKernel((ksize,ksize), 5.0, theta, 10.0, 0.9, 0, ktype=cv2.CV_32F) filtered_image=cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "\n",
    "\n",
    "from skimage.filters.rank import entropy from skimage.morphology import disk\n",
    "\n",
    "\n",
    "entropy_img =entropy(img,disk(5)) plt.imshow(entropy_img)\n",
    "\n",
    "\n",
    "plt.hist(entropy_img.flat,bins=100, range=(0,6)) thresh= threshold_otsu(entropy_img)\n",
    "binary = entropy_img<=thresh plt.imshow(binary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
